{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":396802,"sourceType":"datasetVersion","datasetId":175990}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-04T09:35:07.595950Z","iopub.execute_input":"2024-01-04T09:35:07.596299Z","iopub.status.idle":"2024-01-04T09:35:07.601230Z","shell.execute_reply.started":"2024-01-04T09:35:07.596271Z","shell.execute_reply":"2024-01-04T09:35:07.600233Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nfolder_path = \"/kaggle/input/fashion-product-images-small/images\"\nfile_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\nprint(len(file_names))","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:04:06.320043Z","iopub.execute_input":"2024-01-17T10:04:06.320421Z","iopub.status.idle":"2024-01-17T10:05:51.829818Z","shell.execute_reply.started":"2024-01-17T10:04:06.320373Z","shell.execute_reply":"2024-01-17T10:05:51.828778Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"44441\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"/kaggle/input/fashion-product-images-small/styles.csv\", on_bad_lines=\"skip\")\ncurrent = []\nfor x in df.id.values:\n    if str(x)+\".jpg\" not in file_names:\n        current.append(False)\n    else:\n        current.append(True)\ndf[\"Good\"] = np.array(current)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:05:57.277757Z","iopub.execute_input":"2024-01-17T10:05:57.278533Z","iopub.status.idle":"2024-01-17T10:06:25.305752Z","shell.execute_reply.started":"2024-01-17T10:05:57.278501Z","shell.execute_reply":"2024-01-17T10:06:25.304516Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"      id gender masterCategory subCategory  articleType baseColour  season  \\\n0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n\n     year   usage                             productDisplayName  Good  \n0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  True  \n1  2012.0  Casual             Peter England Men Party Blue Jeans  True  \n2  2016.0  Casual                       Titan Women Silver Watch  True  \n3  2011.0  Casual  Manchester United Men Solid Black Track Pants  True  \n4  2012.0  Casual                          Puma Men Grey T-shirt  True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>masterCategory</th>\n      <th>subCategory</th>\n      <th>articleType</th>\n      <th>baseColour</th>\n      <th>season</th>\n      <th>year</th>\n      <th>usage</th>\n      <th>productDisplayName</th>\n      <th>Good</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15970</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Shirts</td>\n      <td>Navy Blue</td>\n      <td>Fall</td>\n      <td>2011.0</td>\n      <td>Casual</td>\n      <td>Turtle Check Men Navy Blue Shirt</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39386</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Bottomwear</td>\n      <td>Jeans</td>\n      <td>Blue</td>\n      <td>Summer</td>\n      <td>2012.0</td>\n      <td>Casual</td>\n      <td>Peter England Men Party Blue Jeans</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59263</td>\n      <td>Women</td>\n      <td>Accessories</td>\n      <td>Watches</td>\n      <td>Watches</td>\n      <td>Silver</td>\n      <td>Winter</td>\n      <td>2016.0</td>\n      <td>Casual</td>\n      <td>Titan Women Silver Watch</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21379</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Bottomwear</td>\n      <td>Track Pants</td>\n      <td>Black</td>\n      <td>Fall</td>\n      <td>2011.0</td>\n      <td>Casual</td>\n      <td>Manchester United Men Solid Black Track Pants</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53759</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Tshirts</td>\n      <td>Grey</td>\n      <td>Summer</td>\n      <td>2012.0</td>\n      <td>Casual</td>\n      <td>Puma Men Grey T-shirt</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"baseColour\"].unique()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T08:18:14.983686Z","iopub.execute_input":"2024-01-17T08:18:14.984058Z","iopub.status.idle":"2024-01-17T08:18:14.993704Z","shell.execute_reply.started":"2024-01-17T08:18:14.984029Z","shell.execute_reply":"2024-01-17T08:18:14.992597Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['Navy Blue', 'Blue', 'Silver', 'Black', 'Grey', 'Green', 'Purple',\n       'White', 'Beige', 'Brown', 'Bronze', 'Teal', 'Copper', 'Pink',\n       'Off White', 'Maroon', 'Red', 'Khaki', 'Orange', 'Coffee Brown',\n       'Yellow', 'Charcoal', 'Gold', 'Steel', 'Tan', 'Multi', 'Magenta',\n       'Lavender', 'Sea Green', 'Cream', 'Peach', 'Olive', 'Skin',\n       'Burgundy', 'Grey Melange', 'Rust', 'Rose', 'Lime Green', 'Mauve',\n       'Turquoise Blue', 'Metallic', 'Mustard', 'Taupe', 'Nude',\n       'Mushroom Brown', nan, 'Fluorescent Green'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"idx = []\ncategory = []\ncolor = []\nfor a, b, c, d in zip(df.id.values, df.masterCategory.values, df.baseColour.values, df.Good.values):\n    if d:\n        idx.append(a)\n        category.append(b)\n        color.append(c)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:06:33.723867Z","iopub.execute_input":"2024-01-17T10:06:33.724227Z","iopub.status.idle":"2024-01-17T10:06:33.765331Z","shell.execute_reply.started":"2024-01-17T10:06:33.724201Z","shell.execute_reply":"2024-01-17T10:06:33.764534Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame()\ndata[\"id\"] = np.array(idx)\ndata[\"masterCategory\"] = np.array(category)\ndata[\"baseColour\"] = np.array(color)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:48:25.624390Z","iopub.execute_input":"2024-01-17T10:48:25.625148Z","iopub.status.idle":"2024-01-17T10:48:25.674065Z","shell.execute_reply.started":"2024-01-17T10:48:25.625117Z","shell.execute_reply":"2024-01-17T10:48:25.673115Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"colors = ['Black', 'White', 'Blue', 'Brown', 'Grey', 'Red', 'Green', 'Pink', 'Navy Blue', 'Purple']\npreprocess = {}\nfor x, y in enumerate(colors):\n    preprocess[y] = x\nfor x in list(data[\"baseColour\"].unique()):\n    if x not in colors:\n        preprocess[x] = len(colors)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:48:28.268681Z","iopub.execute_input":"2024-01-17T10:48:28.269046Z","iopub.status.idle":"2024-01-17T10:48:28.279095Z","shell.execute_reply.started":"2024-01-17T10:48:28.269016Z","shell.execute_reply":"2024-01-17T10:48:28.277908Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim \nimport torchvision.transforms as transforms\nimport torchvision\nimport os\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import (\n    Dataset,\n    DataLoader,\n)\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize images to the same size\n    transforms.ToTensor(),\n])\n\nclass CustomDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = data\n#         self.preprocess = {}\n#         for x, y in enumerate(self.annotations[\"baseColour\"].unique()):\n#             self.preprocess[y] = x\n        self.annotations[\"baseColour\"] = self.annotations[\"baseColour\"].map(preprocess)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, str(self.annotations.iloc[index, 0])+\".jpg\")\n        image = Image.open(img_path).convert(\"RGB\")\n        y_label = torch.tensor(int(self.annotations.iloc[index, 2]))\n        if self.transform:\n            image = self.transform(image)\n        return (image, y_label)\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyperparameters\nin_channel = 3\nnum_classes = 11\nlearning_rate = 3e-4\nbatch_size = 64\nnum_epochs = 5\n\n# Load Data\ndataset = CustomDataset(\n    csv_file=\"/kaggle/input/fashion-product-images-small/styles.csv\",\n    root_dir=\"/kaggle/input/fashion-product-images-small/images\",\n    transform=transform,\n)\n\ntrain_set, test_set = torch.utils.data.random_split(dataset, [35000, 9419])\ntrain_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n\n# Model\n\nmodel = torchvision.models.googlenet(pretrained = True)\n\nfor param in model.parameters():\n    param.requires_grad = True\n\n# final layer is not frozen\nflts = model.fc.in_features\nmodel.fc = nn.Linear(in_features=flts, out_features=num_classes)\nmodel.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:48:38.248092Z","iopub.execute_input":"2024-01-17T10:48:38.248455Z","iopub.status.idle":"2024-01-17T10:48:43.237905Z","shell.execute_reply.started":"2024-01-17T10:48:38.248424Z","shell.execute_reply":"2024-01-17T10:48:43.236810Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n100%|██████████| 49.7M/49.7M [00:03<00:00, 13.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    losses = []\n\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Get data to cuda if possible\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        # forward\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        losses.append(loss.item())\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # gradient descent or adam step\n        optimizer.step()\n\n    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n\n# Check accuracy on training to see how good our model is\ndef check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n\n    model.train()\n\nprint(\"Checking accuracy on Training Set\")\ncheck_accuracy(train_loader, model)\n\nprint(\"Checking accuracy on Test Set\")\ncheck_accuracy(test_loader, model)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T10:48:54.704867Z","iopub.execute_input":"2024-01-17T10:48:54.705222Z","iopub.status.idle":"2024-01-17T10:59:57.539685Z","shell.execute_reply.started":"2024-01-17T10:48:54.705196Z","shell.execute_reply":"2024-01-17T10:59:57.538652Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Cost at epoch 0 is 1.0503487552105835\nCost at epoch 1 is 0.8417118524066709\nCost at epoch 2 is 0.7438353151355409\nCost at epoch 3 is 0.653000813461091\nCost at epoch 4 is 0.5679955850244658\nChecking accuracy on Training Set\nGot 29498 / 35000 with accuracy 84.28\nChecking accuracy on Test Set\nGot 6711 / 9419 with accuracy 71.25\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, 'fashion-color-googlenet-10c.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:00:56.614112Z","iopub.execute_input":"2024-01-17T11:00:56.614478Z","iopub.status.idle":"2024-01-17T11:00:56.700555Z","shell.execute_reply.started":"2024-01-17T11:00:56.614450Z","shell.execute_reply":"2024-01-17T11:00:56.699578Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"fashion-color-googlenet-10c-state-dict.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-01-17T11:01:01.127560Z","iopub.execute_input":"2024-01-17T11:01:01.128296Z","iopub.status.idle":"2024-01-17T11:01:01.193931Z","shell.execute_reply.started":"2024-01-17T11:01:01.128259Z","shell.execute_reply":"2024-01-17T11:01:01.192713Z"},"trusted":true},"execution_count":13,"outputs":[]}]}